{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de313be0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Imports!\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "\n",
    "from pandas import DataFrame as df\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB as NaiveBayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, GlobalAveragePooling1D, Flatten, Conv1D\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.models import load_model\n",
    "nltk.download('wordnet', quiet = True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04127b9b",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e723d146",
   "metadata": {},
   "source": [
    "## (1) Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a910f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "complete_data = pd.read_csv(\"22203569.csv\", index_col = 0)\n",
    "# Display the data.\n",
    "complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e65ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two categories\n",
    "complete_data['category'].nunique()\n",
    "complete_data.category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1cd77",
   "metadata": {},
   "source": [
    "## (2) Most common terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417beb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = complete_data[['category', 'short_description']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5309193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is an imbalanced problem\n",
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding words more common for each target variable.\n",
    "parenting_class = data[data['category'] == 'PARENTING']['short_description']\n",
    "impact_class = data[data['category'] == 'IMPACT']['short_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82683091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parenting class analysis of most common words.\n",
    "parenting_class.isnull().sum()\n",
    "parenting_class = parenting_class.fillna('')\n",
    "parenting_class.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parenting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parenting_class = pd.DataFrame(parenting_class, columns = [\"short_description\"])\n",
    "df_parenting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b800a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions\n",
    "import contractions\n",
    "\n",
    "def expand_contractions(text):\n",
    "    expanded_text = contractions.fix(text)\n",
    "    return expanded_text\n",
    "\n",
    "# Apply expansion to the 'short_description' column\n",
    "df_parenting_class[\"short_description\"] = df_parenting_class[\"short_description\"].apply(expand_contractions)\n",
    "df_parenting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bcf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the parenting class\n",
    "parenting_class = df_parenting_class[\"short_description\"]\n",
    "parenting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a84fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "words_in_parenting_class = vectorizer.fit_transform(parenting_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ff60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the counts of words in parenting class.\n",
    "tokens_and_counts_parenting_class = zip(vectorizer.get_feature_names_out(), np.asarray(words_in_parenting_class.sum(axis = 0)).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f42b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens_parenting_class = pd.DataFrame(tokens_and_counts_parenting_class, columns = ['Token', 'Count'])\n",
    "df_tokens_parenting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8abd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the words counts\n",
    "df_tokens_parenting_class.sort_values('Count', ascending = False, inplace = True)\n",
    "df_tokens_parenting_class.reset_index(inplace = True, drop = True)\n",
    "df_tokens_parenting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fba339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common words in parenting class.\n",
    "most_common_tokens_parenting_class = df_tokens_parenting_class.nlargest(columns = 'Count', n = 15)\n",
    "most_common_tokens_parenting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825489e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the least common words in parenting class.\n",
    "least_common_tokens_parenting_class = df_tokens_parenting_class.nsmallest(columns = 'Count', n = 15)\n",
    "least_common_tokens_parenting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd00e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the diagram of the most common words and least common words in parenting class.\n",
    "fig, axes = plt.subplots(2, 1, figsize = (20, 8))\n",
    "sns.barplot(ax = axes[0], data = most_common_tokens_parenting_class, x = 'Token', y = 'Count')\n",
    "sns.barplot(ax = axes[1], data = least_common_tokens_parenting_class, x = 'Token', y = 'Count')\n",
    "axes[0].set(ylabel = 'Counts', xlabel = 'Words', title = '%d Most Common Words After Stop Word Removal' % 20)\n",
    "axes[1].set(ylabel = 'Counts', xlabel = 'Words', title = '%d Least Common Words After Stop Word Removal' % 20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact class analysis of most common words.\n",
    "impact_class.isnull().sum()\n",
    "impact_class = impact_class.fillna('')\n",
    "impact_class.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the content of impact class\n",
    "impact_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8208db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_impact_class = pd.DataFrame(impact_class, columns = [\"short_description\"])\n",
    "df_impact_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions\n",
    "import contractions\n",
    "\n",
    "def expand_contractions(text):\n",
    "    expanded_text = contractions.fix(text)\n",
    "    return expanded_text\n",
    "\n",
    "# Apply expansion to the 'short_description' column\n",
    "df_impact_class[\"short_description\"] = df_impact_class[\"short_description\"].apply(expand_contractions)\n",
    "df_impact_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1035128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the impact class\n",
    "impact_class = df_impact_class[\"short_description\"]\n",
    "impact_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd86efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "words_in_impact_class = vectorizer.fit_transform(impact_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the counts of words in impact class.\n",
    "tokens_and_counts_impact_class = zip(vectorizer.get_feature_names_out(), np.asarray(words_in_impact_class.sum(axis = 0)).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76490b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens_impact_class = pd.DataFrame(tokens_and_counts_impact_class, columns = ['Token', 'Count'])\n",
    "df_tokens_impact_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821421cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the words counts\n",
    "df_tokens_impact_class.sort_values('Count', ascending = False, inplace = True)\n",
    "df_tokens_impact_class.reset_index(inplace = True, drop = True)\n",
    "df_tokens_impact_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common words in impact class.\n",
    "most_common_tokens_impact_class = df_tokens_impact_class.nlargest(columns = 'Count', n = 15)\n",
    "most_common_tokens_impact_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2685c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the least common words in impact class.\n",
    "least_common_tokens_impact_class = df_tokens_impact_class.nsmallest(columns = 'Count', n = 15)\n",
    "least_common_tokens_impact_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbac136",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the diagram of the most common words and least common words in impact class.\n",
    "fig, axes = plt.subplots(2, 1, figsize = (20, 8))\n",
    "sns.barplot(ax = axes[0], data = most_common_tokens_impact_class, x = 'Token', y = 'Count')\n",
    "sns.barplot(ax = axes[1], data = least_common_tokens_impact_class, x = 'Token', y = 'Count')\n",
    "axes[0].set(ylabel = 'Counts', xlabel = 'Words', title = '%d Most Common Words After Stop Word Removal' % 20)\n",
    "axes[1].set(ylabel = 'Counts', xlabel = 'Words', title = '%d Least Common Words After Stop Word Removal' % 20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9b689",
   "metadata": {},
   "source": [
    "## (3) Analyse Other Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193827c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, the category - parenting\n",
    "parenting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataframe\n",
    "df_parenting_class = pd.DataFrame(parenting_class, columns = [\"category\", \"short_description\", \"sentence_length\"])\n",
    "df_parenting_class[\"category\"] = \"PARENTING\"\n",
    "df_parenting_class['sentence_length'] = df_parenting_class[\"short_description\"].apply(lambda x: len(x.split()))\n",
    "df_parenting_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the data analysis\n",
    "category_status_parenting = df_parenting_class.groupby('category')['sentence_length'].describe()\n",
    "category_status_parenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb61a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondly, the category - impact\n",
    "impact_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff93e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataframe\n",
    "df_impact_class = pd.DataFrame(impact_class, columns = [\"category\", \"short_description\", \"sentence_length\"])\n",
    "df_impact_class[\"category\"] = \"IMPACT\"\n",
    "df_impact_class['sentence_length'] = df_impact_class[\"short_description\"].apply(lambda x: len(x.split()))\n",
    "df_impact_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea956724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the data analysis\n",
    "category_status_impact = df_impact_class.groupby('category')['sentence_length'].describe()\n",
    "category_status_impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9dfd2",
   "metadata": {},
   "source": [
    "## (4) Check the blank value and drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5af59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the needed data.\n",
    "complete_data = complete_data.loc[:, ['category', 'short_description']]\n",
    "complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ce8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the blank values.\n",
    "complete_data = complete_data.dropna()\n",
    "complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5443e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are blank values in the dataset.\n",
    "complete_data['category'].isnull().sum()\n",
    "complete_data['short_description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c81a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "'''\n",
    "There are 275 blank values in the column of category and short_description, so I\n",
    "dropped them.And because there is no int type values in the dataset, so I did not\n",
    "check the outliers.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff3fb5",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0e253",
   "metadata": {},
   "source": [
    "## (1) Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = complete_data['short_description']\n",
    "y = complete_data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf51173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test = train_test_split(X, y, random_state=0, test_size = 0.30, train_size = 0.7)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_plus_valid, y_train_plus_valid, random_state=0, test_size = 0.199/0.7, train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data = pd.DataFrame(y_train, columns = ['category'])\n",
    "y_train_data\n",
    "y_valid_data = pd.DataFrame(y_valid, columns = ['category'])\n",
    "y_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c5a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the three csv.\n",
    "X_train.to_csv('train.csv', index=True)\n",
    "X_valid.to_csv('valid.csv', index=True)\n",
    "X_test.to_csv('test.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e265e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export y csv.\n",
    "y_train.to_csv('y_train.csv', index=True)\n",
    "y_valid.to_csv('y_valid.csv', index=True)\n",
    "y_test.to_csv('y_test.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486ad7c",
   "metadata": {},
   "source": [
    "## (2) Load train.csv and valid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train.csv and valid.csv.\n",
    "train_data = pd.read_csv('train.csv', index_col=0)\n",
    "valid_data = pd.read_csv('valid.csv', index_col=0)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152609e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the blank value in train.csv.\n",
    "train_data['short_description'].isnull().sum()\n",
    "#train_data['short_description'] = train_data['short_description'].fillna('')\n",
    "#train_data['short_description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the blank value in valid.csv.\n",
    "valid_data['short_description'].isnull().sum()\n",
    "#valid_data['short_description'] = valid_data['short_description'].fillna('')\n",
    "#valid_data['short_description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c48b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions\n",
    "import contractions\n",
    "\n",
    "def expand_contractions(text):\n",
    "    expanded_text = contractions.fix(text)\n",
    "    return expanded_text\n",
    "\n",
    "# Apply expansion to the 'short_description' column\n",
    "train_data[\"short_description\"] = train_data[\"short_description\"].apply(expand_contractions)\n",
    "train_data\n",
    "valid_data[\"short_description\"] = valid_data[\"short_description\"].apply(expand_contractions)\n",
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02abe8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for classification.\n",
    "X_train = train_data['short_description']\n",
    "y_train = y_train_data['category']\n",
    "X_valid = valid_data['short_description']\n",
    "y_valid = y_valid_data['category']\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data.\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1495b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matrix = vectorizer.transform(X_train)\n",
    "X_valid_matrix = vectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e049d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matrix\n",
    "X_valid_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_matrix.shape)\n",
    "print(X_valid_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187de50d",
   "metadata": {},
   "source": [
    "## (3) Build models using two classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the blank value in y_train.\n",
    "y_train.isnull().sum()\n",
    "#y_train = y_train.fillna('')\n",
    "#y_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the DecisionTree to build a model.\n",
    "# Decision Tree is a versatile classifier that can handle both numerical and \n",
    "# categorical data. It builds a tree-like model of decisions and their possible \n",
    "# consequences. Decision Trees are interpretable and can capture complex interactions \n",
    "# between features. They can be particularly effective in text classification tasks\n",
    "# when combined with appropriate feature extraction techniques such as TF-IDF or \n",
    "# word embeddings.\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de33a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change X and y to the dataset I want to evaluate the results in:\n",
    "X_cm = X_train_matrix\n",
    "y_true_labels = y_train\n",
    "model_tree = tree\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_tree.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d635ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(tree, 'DecisionTree_Model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf04a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4931014",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred is a numpy array. It needs to be converted.\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ad23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e360117",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_X_y = pd.concat([X_train,y_train], axis=1)\n",
    "X_train_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83014ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_X_y['y_pred'] = y_pred\n",
    "X_train_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "X_train_X_y.loc[(X_train_X_y['category']=='PARENTING') & (X_train_X_y['y_pred']=='IMPACT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78882032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Naive Bayes to build a model\n",
    "# Naive Bayes is a probabilistic classifier that works well with text data. \n",
    "# It makes use of Bayes' theorem to calculate the probability of a text \n",
    "# belonging to a particular category based on the presence of certain features \n",
    "# (words) in the text. Naive Bayes is known for its simplicity, efficiency, \n",
    "# and effectiveness in text classification tasks.\n",
    "nb = NaiveBayes()\n",
    "nb.fit(X_train_matrix.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change X and y to the dataset I want to evaluate the results in:\n",
    "X_cm = X_train_matrix.toarray()\n",
    "y_true_labels = y_train\n",
    "model_nb = nb\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_nb.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c320cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(nb, 'NaiveBayes_Model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred is a numpy array. It needs to be converted.\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90559d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_X_y_nb = pd.concat([X_train,y_train], axis=1)\n",
    "X_train_X_y_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52095f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_X_y_nb['y_pred'] = y_pred\n",
    "X_train_X_y_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2fe381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "X_train_X_y_nb.loc[(X_train_X_y_nb['category']=='PARENTING') & (X_train_X_y_nb['y_pred']=='IMPACT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b473e4",
   "metadata": {},
   "source": [
    "## (4) Build model using deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train.csv and valid.csv.\n",
    "train_data = pd.read_csv('train.csv', index_col=0)\n",
    "valid_data = pd.read_csv('valid.csv', index_col=0)\n",
    "train_data\n",
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the punctuations in train_data.\n",
    "train_data['short_description'] = train_data['short_description'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca080e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions\n",
    "import contractions\n",
    "\n",
    "def expand_contractions(text):\n",
    "    expanded_text = contractions.fix(text)\n",
    "    return expanded_text\n",
    "\n",
    "# Apply expansion to the 'short_description' column\n",
    "train_data[\"short_description\"] = train_data[\"short_description\"].apply(expand_contractions)\n",
    "train_data[\"short_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the punctuations in valid_data.\n",
    "valid_data['short_description'] = valid_data['short_description'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data[\"short_description\"] = valid_data[\"short_description\"].apply(expand_contractions)\n",
    "valid_data[\"short_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbb56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = train_data['short_description'].values\n",
    "print(sentences_train)\n",
    "sentences_valid = valid_data['short_description'].values\n",
    "print(sentences_valid)\n",
    "y_categories_train = y_train.values\n",
    "print(y_categories_train)\n",
    "y_categories_valid = y_valid.values\n",
    "print(y_categories_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dd915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and covert it into numerical sequences.\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "train_sequences = tokenizer.texts_to_sequences(sentences_train)\n",
    "valid_sequences = tokenizer.texts_to_sequences(sentences_valid)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences_train[0])\n",
    "print(train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e08ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max([len(x) for x in train_sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to ensure consistent length.\n",
    "max_length = 150\n",
    "X_train_data = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "X_valid_data = pad_sequences(valid_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "print(X_train_data[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73047d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train_data.shape)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb114fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_valid_data.shape)\n",
    "X_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2959af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y train labels + Y valid labels.\n",
    "encoder = sklearn.preprocessing.LabelEncoder()\n",
    "category_train_labels = encoder.fit_transform(y_categories_train)\n",
    "y_train_labels = category_train_labels.reshape((3862, 1))\n",
    "print(y_train_labels)\n",
    "category_valid_labels = encoder.fit_transform(y_categories_valid)\n",
    "y_valid_labels = category_valid_labels.reshape((1538, 1))\n",
    "print(y_valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77375ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "history = model.fit(X_train_data, y_train_labels, validation_data=(X_valid_data, y_valid_labels), epochs=10, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4452ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History saves the training into a dictionary structure with the keys below.\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a60a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c393e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "# plt.ylim((-0.1, 1.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4799ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9927ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asfarray(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eaf800",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Change X and y to the dataset I want to evaluate the results in:\n",
    "X_cm = X_train_data\n",
    "y_true_labels = category_train_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2086549",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dcf6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ec0c2",
   "metadata": {},
   "source": [
    "# TASK 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2accc8",
   "metadata": {},
   "source": [
    "## (1) Choose a metric to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7829b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# I chose the accuracy as the primary metric to evaluate my model.\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true_labels, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true_labels, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1_score\n",
    "f1 = f1_score(y_true_labels, y_pred)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abacbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8e36a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"******** Validation Data ********\")\n",
    "# Apply valid model to new dataset\n",
    "X_cm_valid = X_valid_data\n",
    "y_true_labels_valid = category_valid_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred_valid = model.predict(np.asfarray(X_cm_valid)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels_valid, y_pred_valid))\n",
    "cm = confusion_matrix(y_true_labels_valid, y_pred_valid)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validing Evaluation\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true_labels_valid, y_pred_valid)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true_labels_valid, y_pred_valid)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true_labels_valid, y_pred_valid)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1_score\n",
    "f1 = f1_score(y_true_labels_valid, y_pred_valid)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a45d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "'''\n",
    "The choice of a good benchmark for this task depends on the specific dataset,\n",
    "the complexity of the problem, and the performance achieved by existing models or\n",
    "baselines. In this task, I think accuracy provides a general measure of the model's\n",
    "performance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d5957",
   "metadata": {},
   "source": [
    "## (2) Evaluate the performance of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca626deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The First Model - DecisionTree\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66405894",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0492e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a80586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the train dataset.\n",
    "X_cm = X_train_matrix\n",
    "y_true_labels = y_train\n",
    "model_tree = tree\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_tree.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacbd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88050ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the valid dataset.\n",
    "X_cm = X_valid_matrix\n",
    "y_true_labels = y_valid\n",
    "model_tree = tree\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_tree.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "# The performance of the tree model on the train dataset is significantly better\n",
    "# than the validation dataset, indicating potential overfitting. The train set shows\n",
    "# an accuracy of 100% with precision, recall, and F1-score all are 1. However, on the\n",
    "# validation set, the accuracy drops to 78%. This suggests that the model have learned\n",
    "# the specific patterns and nuances of the training data but struggle to generalize\n",
    "# to unseen data. Further investigation is needed to address the overfitting issue,\n",
    "# such as adjusting the modelcomplexity, regularization techniques, or increasing the\n",
    "# amount of training data. It's important to ensure the model can perform well on\n",
    "# real-world data, and additional evaluation and fine-tuning are recommended to improve\n",
    "# their generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1defb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Second Model - Naive Bayes\n",
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the train dataset.\n",
    "X_cm = X_train_matrix.toarray()\n",
    "y_true_labels = y_train\n",
    "model_nb = nb\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_nb.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e674ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the valid dataset.\n",
    "X_cm = X_valid_matrix.toarray()\n",
    "y_true_labels = y_valid\n",
    "model_nb = nb\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_nb.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49acf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "# The performance of the nb model on the train dataset is significantly better\n",
    "# than the validation dataset, indicating potential overfitting. The train set shows\n",
    "# an accuracy of 95% with precision, recall, and F1-score all are 1. However, on the\n",
    "# validation set, the accuracy drops to 75%. This suggests that the model have learned\n",
    "# the specific patterns and nuances of the training data but struggle to generalize\n",
    "# to unseen data. Further investigation is needed to address the overfitting issue,\n",
    "# such as adjusting the modelcomplexity, regularization techniques, or increasing the\n",
    "# amount of training data. It's important to ensure the model can perform well on\n",
    "# real-world data, and additional evaluation and fine-tuning are recommended to improve\n",
    "# their generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19368dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Third Model - Model created by myself\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ab419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a27372",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a60f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the train dataset.\n",
    "X_cm = X_train_data\n",
    "y_true_labels = category_train_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc4407",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the valid dataset.\n",
    "# Apply valid model to new dataset\n",
    "X_cm_valid = X_valid_data\n",
    "y_true_labels_valid = category_valid_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred_valid = model.predict(np.asfarray(X_cm_valid)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels_valid, y_pred_valid))\n",
    "cm = confusion_matrix(y_true_labels_valid, y_pred_valid)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "# The performance of my model on the train dataset is significantly better\n",
    "# than the validation dataset, indicating potential overfitting. The train set shows\n",
    "# an accuracy of 100% with precision, recall, and F1-score all are 1. However, on the\n",
    "# validation set, the accuracy drops to 84%. This suggests that the model have learned\n",
    "# the specific patterns and nuances of the training data but struggle to generalize\n",
    "# to unseen data. Further investigation is needed to address the overfitting issue,\n",
    "# such as adjusting the modelcomplexity, regularization techniques, or increasing the\n",
    "# amount of training data. It's important to ensure the model can perform well on\n",
    "# real-world data, and additional evaluation and fine-tuning are recommended to improve\n",
    "# their generalization capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e76f6",
   "metadata": {},
   "source": [
    "## (3) Perform an error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299e956",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b43e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The First model\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfaa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48890e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model show\n",
    "X_cm = X_train_matrix\n",
    "y_true_labels = y_train\n",
    "model_tree = tree\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_tree.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ad086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted y_train labels\n",
    "y_pred = model_tree.predict(X_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733fd413",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_X_y = pd.concat([X_train,y_train], axis=1)\n",
    "X_train_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_X_y['y_pred'] = y_pred\n",
    "X_train_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a2798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis - train dataset\n",
    "print(X_train_X_y.loc[(X_train_X_y['category']=='PARENTING') & (X_train_X_y['y_pred']=='IMPACT')])\n",
    "print(X_train_X_y.loc[(X_train_X_y['category']=='IMPACT') & (X_train_X_y['y_pred']=='PARENTING')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model show - valid dataset\n",
    "X_cm = X_valid_matrix\n",
    "y_true_labels = y_valid\n",
    "model_tree = tree\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_tree.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid\n",
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd570596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_X_y = pd.concat([X_valid,y_valid], axis=1)\n",
    "X_valid_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_X_y['y_pred'] = y_pred\n",
    "X_valid_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d466fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis - valid dataset\n",
    "print(X_valid_X_y.loc[(X_valid_X_y['category']=='PARENTING') & (X_valid_X_y['y_pred']=='IMPACT')])\n",
    "print(X_valid_X_y.loc[(X_valid_X_y['category']=='IMPACT') & (X_valid_X_y['y_pred']=='PARENTING')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "'''\n",
    "There are 1 error in train dataset and 202+128 errors in valid dataset\n",
    "tested by decisiontree model.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a16c59",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c0386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Second Model\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the train dataset.\n",
    "X_cm = X_train_matrix.toarray()\n",
    "y_true_labels = y_train\n",
    "model_nb = nb\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_nb.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b340f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_X_y = pd.concat([X_train,y_train], axis=1)\n",
    "X_train_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_X_y['y_pred'] = y_pred\n",
    "X_train_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf619c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis - train dataset\n",
    "print(X_train_X_y.loc[(X_train_X_y['category']=='PARENTING') & (X_train_X_y['y_pred']=='IMPACT')])\n",
    "print(X_train_X_y.loc[(X_train_X_y['category']=='IMPACT') & (X_train_X_y['y_pred']=='PARENTING')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da4777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the valid dataset.\n",
    "X_cm = X_valid_matrix.toarray()\n",
    "y_true_labels = y_valid\n",
    "model_nb = nb\n",
    "# Apply valid model to new dataset\n",
    "y_pred = model_nb.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ebef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_X_y = pd.concat([X_valid,y_valid], axis=1)\n",
    "X_valid_X_y\n",
    "X_valid_X_y['y_pred'] = y_pred\n",
    "X_valid_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5390ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis - valid dataset\n",
    "X_valid_X_y.loc[(X_valid_X_y['category']=='PARENTING') & (X_valid_X_y['y_pred']=='IMPACT')]\n",
    "X_valid_X_y.loc[(X_valid_X_y['category']=='IMPACT') & (X_valid_X_y['y_pred']=='PARENTING')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f19ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "'''\n",
    "There are 185 errors in train dataset and 146+233 errors in valid dataset\n",
    "tested by naive bayes model.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ca0bc",
   "metadata": {},
   "source": [
    "### My Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4112e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Third Model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the train dataset.\n",
    "X_cm = X_train_data\n",
    "y_true_labels = category_train_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a63330",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_list = y_pred.tolist()\n",
    "y_pred_list = sum(y_pred_list,[])\n",
    "y_pred_renewed = []\n",
    "for i in y_pred_list:\n",
    "    if i == 0:\n",
    "        y_pred_renewed.append('IMPACT')\n",
    "    elif i == 1:\n",
    "        y_pred_renewed.append('PARENTING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9273773",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_X_y = pd.concat([X_train,y_train], axis=1)\n",
    "X_train_X_y\n",
    "X_train_X_y['y_pred'] = y_pred_renewed\n",
    "X_train_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis - train dataset\n",
    "X_train_X_y.loc[(X_train_X_y['category']=='PARENTING') & (X_train_X_y['y_pred']=='IMPACT')]\n",
    "X_train_X_y.loc[(X_train_X_y['category']=='IMPACT') & (X_train_X_y['y_pred']=='PARENTING')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ac073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the valid dataset.\n",
    "# Apply valid model to new dataset\n",
    "X_cm_valid = X_valid_data\n",
    "y_true_labels_valid = category_valid_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred_valid = model.predict(np.asfarray(X_cm_valid)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels_valid, y_pred_valid))\n",
    "cm = confusion_matrix(y_true_labels_valid, y_pred_valid)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268fa714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renew the element in y_pred into 'IMPACT' or 'PARENTING'\n",
    "y_pred_list = y_pred_valid.tolist()\n",
    "y_pred_list = sum(y_pred_list,[])\n",
    "y_pred_renewed = []\n",
    "for i in y_pred_list:\n",
    "    if i == 0:\n",
    "        y_pred_renewed.append('IMPACT')\n",
    "    elif i == 1:\n",
    "        y_pred_renewed.append('PARENTING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_X_y = pd.concat([X_valid,y_valid], axis=1)\n",
    "X_valid_X_y\n",
    "X_valid_X_y['y_pred'] = y_pred_renewed\n",
    "X_valid_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8905828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis - valid dataset\n",
    "print(X_valid_X_y.loc[(X_valid_X_y['category']=='PARENTING') & (X_valid_X_y['y_pred']=='IMPACT')])\n",
    "print(X_valid_X_y.loc[(X_valid_X_y['category']=='IMPACT') & (X_valid_X_y['y_pred']=='PARENTING')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "'''\n",
    "There is 0 error in train dataset and 265+12 errors in valid dataset\n",
    "tested by my own model.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e650488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the analysis, I have learned that the models, while achieving reasonably\n",
    "# good performance on the training set, struggle when applied to the validation\n",
    "# set. This indicates a certain degree of overfitting, where the models have become\n",
    "# too specialized in capturing the specific patterns present in the training data\n",
    "# and are unable to generalize well to unseen examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fc1c0",
   "metadata": {},
   "source": [
    "## (4) Change each model and redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dacca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the showing graph function.\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb601bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop_words\n",
    "def remove_stopwords(text):\n",
    "    en_stops = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    removed_text = ' '.join([w for w in word_tokens if not w in en_stops])\n",
    "    return removed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02313dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase\n",
    "def lowercase(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lower_words = ' '.join([word.lower() for word in word_tokens])\n",
    "    return lower_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9107c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "def stemming(text):\n",
    "    porter_stemmer=PorterStemmer()\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stemmed_words = ' '.join([porter_stemmer.stem(word=word) for word in word_tokens])\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5982bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "def lemmatize_all(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(text)\n",
    "    tagged_sent = nltk.pos_tag(word_tokens)\n",
    "    for word, tag in tagged_sent:\n",
    "        if tag.startswith('NN'):\n",
    "            yield wnl.lemmatize(word, pos='n')\n",
    "        elif tag.startswith('VB'):\n",
    "            yield wnl.lemmatize(word, pos='v')\n",
    "        elif tag.startswith('JJ'):\n",
    "            yield wnl.lemmatize(word, pos='a')\n",
    "        elif tag.startswith('R'):\n",
    "            yield wnl.lemmatize(word, pos='r')\n",
    "        else:\n",
    "            yield word\n",
    "def merge(text):\n",
    "    all_words = lemmatize_all(text)\n",
    "    return ' '.join(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand function\n",
    "def expand_contractions(text):\n",
    "    expanded_text = contractions.fix(text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea48658a",
   "metadata": {},
   "source": [
    "### I: DecisionTree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1e183",
   "metadata": {},
   "source": [
    "#### Tree Previous Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous Model\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55319ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "X_cm = X_train_matrix.toarray()\n",
    "y_true_labels = y_train\n",
    "model_tree = tree\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_tree.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d3388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validing Dataset\n",
    "X_cm = X_valid_matrix\n",
    "y_true_labels = y_valid\n",
    "model_tree = tree\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_tree.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784de2f",
   "metadata": {},
   "source": [
    "#### Tree New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4897a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train.csv and valid.csv.\n",
    "train_data = pd.read_csv('train.csv', index_col=0)\n",
    "valid_data = pd.read_csv('valid.csv', index_col=0)\n",
    "X_train = train_data['short_description']\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba66a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processing\n",
    "train_data['short_description'] = train_data['short_description'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "train_data['short_description'] = train_data['short_description'].apply(lowercase)\n",
    "train_data['short_description'] = train_data['short_description'].apply(expand_contractions)\n",
    "train_data['short_description'] = train_data['short_description'].apply(merge)\n",
    "X_train_processed = train_data['short_description']\n",
    "X_train_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data.\n",
    "vectorizer_tree_improve = CountVectorizer(stop_words = 'english')\n",
    "vectorizer_tree_improve.fit(X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1a7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matrix_processed = vectorizer_tree_improve.transform(X_train_processed)\n",
    "X_train_matrix_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce533ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_improve_model = DecisionTreeClassifier()\n",
    "tree_improve_model.fit(X_train_matrix_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e00df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "X_cm = X_train_matrix_processed\n",
    "y_true_labels = y_train\n",
    "# Apply trained model to new dataset\n",
    "y_pred = tree_improve_model.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb0770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = valid_data['short_description']\n",
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processing\n",
    "valid_data['short_description'] = valid_data['short_description'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "valid_data['short_description'] = valid_data['short_description'].apply(lowercase)\n",
    "valid_data['short_description'] = valid_data['short_description'].apply(expand_contractions)\n",
    "valid_data['short_description'] = valid_data['short_description'].apply(merge)\n",
    "X_valid_processed = valid_data['short_description']\n",
    "X_valid_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_matrix_processed = vectorizer_tree_improve.transform(X_valid_processed)\n",
    "X_valid_matrix_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validing Dataset\n",
    "X_cm = X_valid_matrix_processed\n",
    "y_true_labels = y_valid\n",
    "y_pred = tree_improve_model.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70deb631",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e70a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_improve_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(tree_improve_model, 'DecisionTree_Improve_Model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc7fb8",
   "metadata": {},
   "source": [
    "### II: Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ccb3a",
   "metadata": {},
   "source": [
    "#### Bayes Previous Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous Model\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9cfccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "X_cm = X_train_matrix.toarray()\n",
    "y_true_labels = y_train\n",
    "model_nb = nb\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_nb.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440dfdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validing Dataset\n",
    "X_cm = X_valid_matrix.toarray()\n",
    "y_true_labels = y_valid\n",
    "model_nb = nb\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_nb.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7317861c",
   "metadata": {},
   "source": [
    "#### New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processed Text\n",
    "X_train_matrix_processed\n",
    "X_valid_matrix_processed\n",
    "y_train\n",
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a83b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build new model\n",
    "nb_improve_model = NaiveBayes()\n",
    "nb_improve_model.fit(X_train_matrix_processed.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "X_cm = X_train_matrix_processed.toarray()\n",
    "y_true_labels = y_train\n",
    "y_pred = nb_improve_model.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validing Dataset\n",
    "X_cm = X_valid_matrix_processed.toarray()\n",
    "y_true_labels = y_valid\n",
    "y_pred = nb_improve_model.predict(X_cm)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade44fa5",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b4990",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_improve_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(nb_improve_model, 'NaiveBayes_Improve_Model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068f3c5",
   "metadata": {},
   "source": [
    "### III: My Own Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d05721",
   "metadata": {},
   "source": [
    "#### Previous Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous Model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset.\n",
    "X_cm = X_train_data\n",
    "y_true_labels = category_train_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validing Dataset.\n",
    "X_cm = X_valid_data\n",
    "y_true_labels = category_valid_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous Accuracy\n",
    "# history = model.fit(X_train_data, y_train_labels, validation_data=(X_valid_data, y_valid_labels), epochs=10, batch_size=32, verbose=False)\n",
    "loss, accuracy = model.evaluate(X_train_data, y_train_labels, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_valid_data, y_valid_labels, verbose=False)\n",
    "print(\"Validing Accuracy: {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff0aeec",
   "metadata": {},
   "source": [
    "#### New Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3fdc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving Text\n",
    "X_train_processed\n",
    "X_valid_processed\n",
    "y_train_labels\n",
    "y_valid_labels\n",
    "category_train_labels\n",
    "category_valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train_processed = X_train_processed.values\n",
    "print(sentences_train_processed)\n",
    "sentences_valid_processed = X_valid_processed.values\n",
    "print(sentences_valid_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and covert it into numerical sequences.\n",
    "tokenizer_processed = Tokenizer()\n",
    "tokenizer_processed.fit_on_texts(sentences_train_processed)\n",
    "train_sequences_processed = tokenizer_processed.texts_to_sequences(sentences_train_processed)\n",
    "valid_sequences_processed = tokenizer_processed.texts_to_sequences(sentences_valid_processed)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size_train = len(tokenizer_processed.word_index) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f635c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer_processed.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max([len(x) for x in train_sequences_processed]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to ensure consistent length.\n",
    "max_length = 150\n",
    "X_train_data_processed = pad_sequences(train_sequences_processed, maxlen=max_length, padding='post')\n",
    "X_valid_data_processed = pad_sequences(valid_sequences_processed, maxlen=max_length, padding='post')\n",
    "\n",
    "print(X_train_data_processed[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2058e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model_improve1 = Sequential()\n",
    "model_improve1.add(Embedding(input_dim=vocab_size_train, output_dim=embedding_dim, input_length=max_length))\n",
    "model_improve1.add(Flatten())\n",
    "model_improve1.add(Dense(10, activation='relu'))\n",
    "model_improve1.add(Dense(1, activation='sigmoid'))\n",
    "model_improve1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_improve1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "history_improved1 = model_improve1.fit(X_train_data_processed, y_train_labels, validation_data=(X_valid_data_processed, y_valid_labels), epochs=10, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebe96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History saves the training into a dictionary structure with the keys below.\n",
    "history_improved1.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history_improved1.history['accuracy'])\n",
    "plt.plot(history_improved1.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "X_cm = X_train_data_processed\n",
    "y_true_labels = category_train_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_improve1.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validing Dataset\n",
    "X_cm = X_valid_data_processed\n",
    "y_true_labels = category_valid_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_improve1.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea649013",
   "metadata": {},
   "source": [
    "#### New Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buidling a Better Model\n",
    "embedding_dim = 100\n",
    "\n",
    "model_improve2 = Sequential()\n",
    "model_improve2.add(Embedding(input_dim=vocab_size_train, output_dim=embedding_dim, input_length=max_length))\n",
    "model_improve2.add(GlobalAveragePooling1D())\n",
    "model_improve2.add(Dense(10, activation='relu'))\n",
    "model_improve2.add(Dense(1, activation='sigmoid'))\n",
    "model_improve2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_improve2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27481b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History\n",
    "history_improve2 = model_improve2.fit(X_train_data_processed, y_train_labels, validation_data=(X_valid_data_processed, y_valid_labels), epochs=10, batch_size=32, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a37d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving Model\n",
    "loss, accuracy = model_improve2.evaluate(X_train_data_processed, y_train_labels, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model_improve2.evaluate(X_valid_data_processed, y_valid_labels, verbose=False)\n",
    "print(\"Validing Accuracy: {:.4f}\".format(accuracy))\n",
    "plot_history(history_improve2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ac921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "X_cm = X_train_data_processed\n",
    "y_true_labels = category_train_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_improve2.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validing Dataset.\n",
    "X_cm = X_valid_data_processed\n",
    "y_true_labels = category_valid_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_improve2.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39763664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model_improve2.save('model_improve2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bb69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "best_model = load_model('model_improve2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d998b",
   "metadata": {},
   "source": [
    "#### New Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521959e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imrpoving model again\n",
    "embedding_dim = 100\n",
    "\n",
    "model_improve3 = Sequential()\n",
    "model_improve3.add(Embedding(input_dim=vocab_size_train, output_dim=embedding_dim, input_length=max_length))\n",
    "model_improve3.add(Conv1D(128, 5, activation='relu'))\n",
    "model_improve3.add(GlobalAveragePooling1D())\n",
    "model_improve3.add(Dense(10, activation='relu'))\n",
    "model_improve3.add(Dense(1, activation='sigmoid'))\n",
    "model_improve3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_improve3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History\n",
    "history_improve3 = model_improve3.fit(X_train_data_processed, y_train_labels, validation_data=(X_valid_data_processed, y_valid_labels), epochs=10, batch_size=32, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce47b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving Model again\n",
    "loss, accuracy = model_improve3.evaluate(X_train_data_processed, y_train_labels, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model_improve3.evaluate(X_valid_data_processed, y_valid_labels, verbose=False)\n",
    "print(\"Validing Accuracy: {:.4f}\".format(accuracy))\n",
    "plot_history(history_improve3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "X_cm = X_train_data_processed\n",
    "y_true_labels = category_train_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_improve3.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4cd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validing Dataset.\n",
    "X_cm = X_valid_data_processed\n",
    "y_true_labels = category_valid_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_improve3.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5780b",
   "metadata": {},
   "source": [
    "## (5) Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train.csv and valid.csv.\n",
    "train_data = pd.read_csv('train.csv', index_col=0)\n",
    "valid_data = pd.read_csv('valid.csv', index_col=0)\n",
    "train_data\n",
    "#valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ee682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and validation sets\n",
    "X_merged = np.concatenate((train_data, valid_data))\n",
    "y_merged = np.concatenate((y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_merged_df = pd.DataFrame(X_merged, columns = ['short_description'])\n",
    "X_merged_df\n",
    "y_merged_df = pd.DataFrame(y_merged, columns = ['category'])\n",
    "y_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processing\n",
    "X_merged_df[\"short_description\"] = X_merged_df[\"short_description\"].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "X_merged_df[\"short_description\"] = X_merged_df[\"short_description\"].apply(lowercase)\n",
    "X_merged_df[\"short_description\"] = X_merged_df[\"short_description\"].apply(expand_contractions)\n",
    "X_merged_df[\"short_description\"] = X_merged_df[\"short_description\"].apply(merge)\n",
    "X_merged_processed = X_merged_df[\"short_description\"]\n",
    "X_merged_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_merged = X_merged_processed.values\n",
    "print(sentences_merged)\n",
    "categories_merged = y_merged_df['category'].values\n",
    "print(categories_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be17a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and covert it into numerical sequences.\n",
    "tokenizer_merged = Tokenizer()\n",
    "tokenizer_merged.fit_on_texts(sentences_merged)\n",
    "merged_sequences = tokenizer_merged.texts_to_sequences(sentences_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63851543",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_merged = len(tokenizer_merged.word_index) + 1 \n",
    "vocab_size_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences_merged[0])\n",
    "print(merged_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdecefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to ensure consistent length.\n",
    "max_length = 150\n",
    "merged_data = pad_sequences(merged_sequences, maxlen=max_length, padding='post')\n",
    "print(merged_data)\n",
    "#print(merged_data[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_merged labels\n",
    "encoder_merged = sklearn.preprocessing.LabelEncoder()\n",
    "category_merged_labels = encoder_merged.fit_transform(categories_merged)\n",
    "merged_labels = category_merged_labels.reshape((5400, 1))\n",
    "print(category_merged_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d717c",
   "metadata": {},
   "source": [
    "### DecisionTree Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_decisiontree_improve = joblib.load('DecisionTree_Improve_Model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827cdc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(model_decisiontree_improve, merged_data, merged_labels, cv=5, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c68b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72ef7d",
   "metadata": {},
   "source": [
    "### Naive Bayes Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_naivebayes_improve = joblib.load('NaiveBayes_Improve_Model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e0a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(model_naivebayes_improve, merged_data, merged_labels, cv=5, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270b9fc",
   "metadata": {},
   "source": [
    "### My Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eaae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "best_model = load_model('model_improve2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad76a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    embedding_dim = 100\n",
    "    model_my_final = Sequential()\n",
    "    model_my_final.add(Embedding(input_dim=vocab_size_merged, output_dim=embedding_dim, input_length=max_length))\n",
    "    model_my_final.add(Conv1D(128, 5, activation='relu'))\n",
    "    model_my_final.add(GlobalAveragePooling1D())\n",
    "    model_my_final.add(Dense(10, activation='relu'))\n",
    "    model_my_final.add(Dense(1, activation='sigmoid'))\n",
    "    model_my_final.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model_my_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c41c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f = KerasClassifier(model=create_model, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b97df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(model_f, merged_data, merged_labels, cv=5, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cce18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment\n",
    "'''\n",
    "Based on the provided socres, it appears that the model is performing fairly well.\n",
    "The average accuracy across the five folds of cross-validation is around 83%-84%,\n",
    "which indicates that the model is able to classify the articles with a good level\n",
    "of accuracy.\n",
    "\n",
    "However, it is important to note that accuracy alone may not provide a complete picture\n",
    "of the model's performance, especially if the dataset is imbalanced or if there are\n",
    "specific classes that are more important to classify correctly than others.Therefore, \n",
    "it's recommended to consider other evaluation metrics such as precision, recall, \n",
    "and F1-score to assess the model's performance more comprehensively.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3bda2",
   "metadata": {},
   "source": [
    "## (6) Apply to Test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160dd7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test.csv.\n",
    "test_data = pd.read_csv('test.csv', index_col=0)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36db396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are blank values in the dataset.\n",
    "test_data['short_description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcbb0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processing\n",
    "test_data['short_description'] = test_data['short_description'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "test_data['short_description'] = test_data['short_description'].apply(lowercase)\n",
    "test_data['short_description'] = test_data['short_description'].apply(expand_contractions)\n",
    "test_data['short_description'] = test_data['short_description'].apply(merge)\n",
    "X_test_processed = test_data['short_description']\n",
    "X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d005a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_matrix_processed = vectorizer_tree_improve.transform(X_test_processed)\n",
    "X_test_matrix_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a53658f",
   "metadata": {},
   "source": [
    "#### My Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6dc536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "best_model = load_model('model_improve2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adef2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_test_processed = X_test_processed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93fd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences_processed = tokenizer_processed.texts_to_sequences(sentences_test_processed)\n",
    "# Pad the sequences to ensure consistent length.\n",
    "max_length = 150\n",
    "X_test_data_processed = pad_sequences(test_sequences_processed, maxlen=max_length, padding='post')\n",
    "X_test_data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_categories_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ef44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y test labels.\n",
    "encoder = sklearn.preprocessing.LabelEncoder()\n",
    "category_test_labels = encoder.fit_transform(y_categories_test)\n",
    "y_test_labels = category_test_labels.reshape((2318, 1))\n",
    "print(y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Dataset.\n",
    "X_cm = X_test_data_processed\n",
    "y_true_labels = category_test_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = best_model.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff83a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "'''\n",
    "The results of accuracy is similar to the one I obtained for the validation set.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c363f1",
   "metadata": {},
   "source": [
    "## (7) Retrain the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78faab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Valid data merge\n",
    "X_merged_df = pd.DataFrame(X_merged, columns = ['short_description'])\n",
    "X_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b678a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_merged_df = pd.DataFrame(y_merged, columns = ['category'])\n",
    "y_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fde4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_valid_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9419697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "X_merged_df[\"short_description\"] = X_merged_df[\"short_description\"].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "X_merged_df[\"short_description\"] = X_merged_df[\"short_description\"].apply(lowercase)\n",
    "X_merged_df[\"short_description\"] = X_merged_df[\"short_description\"].apply(expand_contractions)\n",
    "X_merged_df[\"short_description\"] = X_merged_df[\"short_description\"].apply(merge)\n",
    "X_merged_processed = X_merged_df[\"short_description\"]\n",
    "X_merged_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_merged = X_merged_processed.values\n",
    "print(sentences_merged)\n",
    "categories_merged = y_merged_df['category'].values\n",
    "print(categories_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text and covert it into numerical sequences.\n",
    "tokenizer_merged = Tokenizer()\n",
    "tokenizer_merged.fit_on_texts(sentences_merged)\n",
    "merged_sequences = tokenizer_merged.texts_to_sequences(sentences_merged)\n",
    "valid_sequences = tokenizer_merged.texts_to_sequences(sentences_valid_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa80f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_merged = len(tokenizer_merged.word_index) + 1 \n",
    "vocab_size_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ac4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max([len(x) for x in merged_sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db47c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to ensure consistent length.\n",
    "max_length = 150\n",
    "merged_data = pad_sequences(merged_sequences, maxlen=max_length, padding='post')\n",
    "valid_data = pad_sequences(valid_sequences, maxlen=max_length, padding='post')\n",
    "print(merged_data)\n",
    "#print(merged_data[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_merged labels\n",
    "encoder_merged = sklearn.preprocessing.LabelEncoder()\n",
    "category_merged_labels = encoder_merged.fit_transform(categories_merged)\n",
    "merged_labels = category_merged_labels.reshape((5400, 1))\n",
    "print(category_merged_labels)\n",
    "category_valid_labels = encoder_merged.fit_transform(y_categories_valid)\n",
    "valid_labels = category_valid_labels.reshape((1538, 1))\n",
    "print(category_valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f67af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buidling a Better Model\n",
    "embedding_dim = 100\n",
    "\n",
    "model_retrain = Sequential()\n",
    "model_retrain.add(Embedding(input_dim=vocab_size_merged, output_dim=embedding_dim, input_length=max_length))\n",
    "model_retrain.add(GlobalAveragePooling1D())\n",
    "model_retrain.add(Dense(10, activation='relu'))\n",
    "model_retrain.add(Dense(1, activation='sigmoid'))\n",
    "model_retrain.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_retrain.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History\n",
    "history_retrain = model_retrain.fit(merged_data, merged_labels, validation_data=(valid_data, valid_labels), epochs=10, batch_size=32, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "# Load the test.csv.\n",
    "test_data = pd.read_csv('test.csv', index_col=0)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f515e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data preprocessing\n",
    "test_data['short_description'] = test_data['short_description'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "test_data['short_description'] = test_data['short_description'].apply(lowercase)\n",
    "test_data['short_description'] = test_data['short_description'].apply(expand_contractions)\n",
    "test_data['short_description'] = test_data['short_description'].apply(merge)\n",
    "X_test_processed = test_data['short_description']\n",
    "X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_test_processed = X_test_processed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data preprocessing\n",
    "test_sequences_processed = tokenizer_merged.texts_to_sequences(sentences_test_processed)\n",
    "# Pad the sequences to ensure consistent length.\n",
    "max_length = 150\n",
    "X_test_data_processed = pad_sequences(test_sequences_processed, maxlen=max_length, padding='post')\n",
    "X_test_data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc839e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_categories_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y test labels.\n",
    "encoder = sklearn.preprocessing.LabelEncoder()\n",
    "category_test_labels = encoder.fit_transform(y_categories_test)\n",
    "y_test_labels = category_test_labels.reshape((2318, 1))\n",
    "print(y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Dataset.\n",
    "X_cm = X_test_data_processed\n",
    "y_true_labels = category_test_labels\n",
    "# Apply trained model to new dataset\n",
    "y_pred = model_retrain.predict(np.asfarray(X_cm)).round()\n",
    "#y_pred = (y_pred > 0.5).astype(int)\n",
    "#classes = np.argmax(y_pred, axis=1)\n",
    "#metrics.f1_score(y_true_labels, y_pred,average='weighted',zero_division=0)\n",
    "print(metrics.classification_report(y_true_labels, y_pred))\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0bd6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment:\n",
    "'''\n",
    "The accuracy of one category of the retrained model seems to be improved \n",
    "from 62% to 69%.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c4370",
   "metadata": {},
   "source": [
    "## (8) Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c49344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
